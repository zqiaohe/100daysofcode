{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[homework]segmentation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zqiaohe/100daysofcode/blob/master/%5Bhomework%5Dsegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "i4_SAVxHZ0zi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<p style=\"align: center;\"><img align=center src=\"https://s8.hostingkartinok.com/uploads/images/2018/08/308b49fcfbc619d629fe4604bceb67ac.jpg\" style=\"height:400px;\" width=500px/></p>\n",
        "\n",
        "<h3 style=\"text-align: center;\"><b>Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ</b></h3>"
      ]
    },
    {
      "metadata": {
        "id": "YrxYKOhsZ0zm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "xSYK7CmzZ0zr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h3 style=\"text-align: center;\"><b>Домашнее задание: сегментация изображений</b></h3>"
      ]
    },
    {
      "metadata": {
        "id": "y9SEpazGZ0zu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "PHfnUAvTZ0zy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h3 style=\"text-align: center;\"><b>Условие</b></h3>"
      ]
    },
    {
      "metadata": {
        "id": "AN9TV1JcZ0z0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "В качестве домашней работы предлагается улучшить сегментацию, сделанную на семинаре. В качестве основы для даталоэдера используйте функцию __keras_generator__. Попробуйте сделать следующие улучшения:\n",
        "1. Брать случайный кроп, а не ресайзить исходное изображение. Попробуйте разные размеры кропов, на каких результат получается лучше? Кроп какого максимального размера помещается в вашу видеокарту?\n",
        "2. Добавить аугментаций. Например, можно поворачивать картинки или добавлять случайный шум\n",
        "\n",
        "Эти два пункта улучшения можно сделать с помощью библиотеки __albumentations__ https://github.com/albu/albumentations . Пример использования можно посмотреть в конце семинарского ноутбука."
      ]
    },
    {
      "metadata": {
        "id": "IbUE_FdANwt9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AbMPQTQtW2xY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3e8db0e-a3b6-4389-938d-40216bf90338"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xfHaaXbeW3_H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!unzip /content/gdrive/My\\ Drive/[11]segmentation/data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1rtLarbD9tvm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rle_decode(mask_rle, shape=(1280, 1918, 1)):\n",
        "    '''\n",
        "    mask_rle: run-length as string formated (start length)\n",
        "    shape: (height,width) of array to return \n",
        "    Returns numpy array, 1 - mask, 0 - background\n",
        "    '''\n",
        "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
        "\n",
        "    s = mask_rle.split()\n",
        "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
        "    starts -= 1\n",
        "    ends = starts + lengths    \n",
        "    for lo, hi in zip(starts, ends):\n",
        "        img[lo:hi] = 1\n",
        "        \n",
        "    img = img.reshape(shape)\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eKbbZSUnJqgA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from albumentations import (\n",
        "    CLAHE, RandomRotate90, Transpose, RandomCrop, Resize, ShiftScaleRotate, Blur, OpticalDistortion, \n",
        "    GridDistortion, HueSaturationValue, IAAAdditiveGaussianNoise, GaussNoise, MotionBlur, \n",
        "    MedianBlur, IAAPiecewiseAffine, IAASharpen, IAAEmboss, RandomContrast, RandomBrightness, \n",
        "    Flip, HorizontalFlip, OneOf, Compose, PadIfNeeded, LongestMaxSize, PadIfNeeded, ElasticTransform,Cutout\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def strong_aug(p=1.0):\n",
        "    return Compose([\n",
        "        ShiftScaleRotate(shift_limit=0.125, scale_limit=0.2, rotate_limit=10, p=0.7, border_mode=cv2.BORDER_CONSTANT),\n",
        "        RandomCrop(256, 256),\n",
        "        #PadIfNeeded(min_height=224, min_width=224, border_mode=cv2.BORDER_CONSTANT, p=1.0),\n",
        "        #Resize(64, 64),\n",
        "        RandomRotate90(),\n",
        "        ElasticTransform(1.), \n",
        "        HorizontalFlip(),\n",
        "        #Cutout(p=1.),\n",
        "        Transpose(),\n",
        "        OneOf([\n",
        "            IAAAdditiveGaussianNoise(),\n",
        "            GaussNoise(),\n",
        "        ], p=0.3),\n",
        "        OneOf([\n",
        "            MotionBlur(p=.4),\n",
        "            MedianBlur(blur_limit=3, p=0.3),\n",
        "            Blur(blur_limit=3, p=0.3),\n",
        "        ], p=0.5),\n",
        "        OneOf([\n",
        "            OpticalDistortion(p=0.3),\n",
        "            GridDistortion(p=0.1),\n",
        "            IAAPiecewiseAffine(p=0.3),\n",
        "        ], p=0.5),\n",
        "        OneOf([\n",
        "            CLAHE(clip_limit=3),\n",
        "            IAASharpen(),\n",
        "            IAAEmboss(),\n",
        "            RandomContrast(),\n",
        "            RandomBrightness(),\n",
        "        ], p=0.4),\n",
        "        HueSaturationValue(p=0.7),\n",
        "         \n",
        "        \n",
        "        \n",
        "    ],\n",
        "        p=p)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a0TtW91XnDxQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('data/train_masks.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uqvNNu2tnEm_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df = df[:4000]\n",
        "val_df = df[4000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0pUt2DfggSvj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def keras_generator(gen_df, batch_size, aug):\n",
        "    while True:\n",
        "        x_batch = []\n",
        "        y_batch = []\n",
        "        \n",
        "        for i in range(batch_size):\n",
        "            img_name, mask_rle = gen_df.sample(1).values[0]\n",
        "            img = cv2.imread('data/train/{}'.format(img_name))\n",
        "            mask = rle_decode(mask_rle)\n",
        "            if aug == 0:\n",
        "              img = cv2.resize(img, (256, 256))\n",
        "              mask = cv2.resize(mask, (256, 256))\n",
        "            else:\n",
        "              augmentation = strong_aug(p=1.0)\n",
        "              data = {'image': img.astype('uint8'), 'mask': mask.astype('uint8')}\n",
        "              augmented = augmentation(**data)\n",
        "              img, mask = augmented[\"image\"], augmented[\"mask\"]\n",
        "            \n",
        "            x_batch += [img]\n",
        "            y_batch += [mask]\n",
        "\n",
        "        x_batch = np.array(x_batch) / 255.\n",
        "        y_batch = np.array(y_batch)\n",
        "        \n",
        "        if aug == 1:\n",
        "          yield x_batch, y_batch\n",
        "        else:\n",
        "          yield x_batch, np.expand_dims(y_batch, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hfuUsjAzZ00B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Подумайте, нужно ли применять аугментации для валидационной выборки или это стоит делать только для тренировки? Возможно, следует добавить в аргументы __keras_generator__ флаг, который будет говорить, применять аугментации или нет.\n",
        "3. В качестве модели машинного обучения предлагается взять либо модель с семинара, либо какую-нибудь готовую реализацию, например из __segmentation_models__ https://github.com/qubvel/segmentation_models . Пример использования:"
      ]
    },
    {
      "metadata": {
        "id": "vtROIExb9BcT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "outputId": "5d3617b5-bda0-4601-dfe3-d941774fbb34"
      },
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/qubvel/segmentation_models"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/qubvel/segmentation_models\n",
            "  Cloning https://github.com/qubvel/segmentation_models to /tmp/pip-req-build-q8wd6_yh\n",
            "Requirement already satisfied: keras>=2.1.4 in /usr/local/lib/python3.6/dist-packages (from segmentation-models==0.1.2) (2.2.4)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from segmentation-models==0.1.2) (0.13.1)\n",
            "Collecting image-classifiers==0.1.0rc0 (from segmentation-models==0.1.2)\n",
            "  Downloading https://files.pythonhosted.org/packages/55/10/80588eb0b79b51d0eb31f47896e8b4f9588f0328cbb44f4abfb5e6a1b8be/image_classifiers-0.1.0rc0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.4->segmentation-models==0.1.2) (1.14.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.4->segmentation-models==0.1.2) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.4->segmentation-models==0.1.2) (1.0.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.4->segmentation-models==0.1.2) (1.0.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.4->segmentation-models==0.1.2) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.4->segmentation-models==0.1.2) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.1.4->segmentation-models==0.1.2) (1.11.0)\n",
            "Requirement already satisfied: networkx>=1.8 in /usr/local/lib/python3.6/dist-packages (from scikit-image->segmentation-models==0.1.2) (2.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->segmentation-models==0.1.2) (1.0.1)\n",
            "Requirement already satisfied: matplotlib>=1.3.1 in /usr/local/lib/python3.6/dist-packages (from scikit-image->segmentation-models==0.1.2) (3.0.2)\n",
            "Requirement already satisfied: pillow>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->segmentation-models==0.1.2) (4.0.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=1.8->scikit-image->segmentation-models==0.1.2) (4.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image->segmentation-models==0.1.2) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image->segmentation-models==0.1.2) (1.0.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image->segmentation-models==0.1.2) (2.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.3.1->scikit-image->segmentation-models==0.1.2) (2.5.3)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=2.1.0->scikit-image->segmentation-models==0.1.2) (0.46)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.3.1->scikit-image->segmentation-models==0.1.2) (40.6.3)\n",
            "Building wheels for collected packages: segmentation-models\n",
            "  Running setup.py bdist_wheel for segmentation-models ... \u001b[?25l-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-x0yvc3ry/wheels/49/cf/46/cbb4bb64518c402aea99df9d466f1081450597e653256bbcf4\n",
            "Successfully built segmentation-models\n",
            "Installing collected packages: image-classifiers, segmentation-models\n",
            "Successfully installed image-classifiers-0.1.0rc0 segmentation-models-0.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "p8Eky1B19WrM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v6_QnUfDZ00D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "outputId": "15ad4f98-ed27-4ec5-a691-3fa45b3522a9"
      },
      "cell_type": "code",
      "source": [
        "from segmentation_models import Unet\n",
        "from segmentation_models.backbones import get_preprocessing\n",
        "\n",
        "for x, y in keras_generator(train_df, 10, 1):\n",
        "    break\n",
        "preprocessing_fn = get_preprocessing('resnet34')\n",
        "x = preprocessing_fn(x)\n",
        "\n",
        "# prepare model\n",
        "model = Unet(backbone_name='densenet121', encoder_weights='imagenet')\n",
        "model.compile('Adam', 'binary_crossentropy', ['binary_accuracy'])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "29089792/29084464 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eoIPN2GoAlw7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "b6c27d7f-1c2e-44a6-fd7a-7379fb38bd2e"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x,y,epochs = 10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 31s 3s/step - loss: 0.7968 - binary_accuracy: 0.4243\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 0.6791 - binary_accuracy: 0.5688\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 0.5483 - binary_accuracy: 0.7594\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.4435 - binary_accuracy: 0.9017\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.3798 - binary_accuracy: 0.9748\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 0.3288 - binary_accuracy: 0.9679\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.2887 - binary_accuracy: 0.9895\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.2628 - binary_accuracy: 0.9883\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.2437 - binary_accuracy: 0.9941\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 0.2288 - binary_accuracy: 0.9964\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcaaa03f048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "2QNS3VMTCJKv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "preprocessing_fn = get_preprocessing('vgg16')\n",
        "x = preprocessing_fn(x)\n",
        "\n",
        "# prepare model\n",
        "model = Unet(backbone_name='vgg16', encoder_weights='imagenet')\n",
        "model.compile('Adam', 'binary_crossentropy', ['binary_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dtChLJg4CW_n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "17d171ae-e94f-4714-c6b6-09d43d6cde01"
      },
      "cell_type": "code",
      "source": [
        "model.fit(x,y,epochs = 10)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "10/10 [==============================] - 15s 2s/step - loss: 0.7057 - binary_accuracy: 0.1864\n",
            "Epoch 2/10\n",
            "10/10 [==============================] - 1s 67ms/step - loss: 0.6733 - binary_accuracy: 0.8467\n",
            "Epoch 3/10\n",
            "10/10 [==============================] - 1s 67ms/step - loss: 0.6498 - binary_accuracy: 0.8505\n",
            "Epoch 4/10\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 0.6374 - binary_accuracy: 0.8521\n",
            "Epoch 5/10\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 0.6287 - binary_accuracy: 0.8505\n",
            "Epoch 6/10\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 0.6230 - binary_accuracy: 0.8531\n",
            "Epoch 7/10\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 0.6173 - binary_accuracy: 0.8554\n",
            "Epoch 8/10\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 0.6123 - binary_accuracy: 0.8554\n",
            "Epoch 9/10\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 0.6072 - binary_accuracy: 0.8554\n",
            "Epoch 10/10\n",
            "10/10 [==============================] - 1s 66ms/step - loss: 0.6019 - binary_accuracy: 0.8554\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcaaa0cbdd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "mIe_PJNTZ00J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "В качестве базового энкодера на семинаре использовался __resnet50__. Поэкспериментируйте с разными энкодерами, например, __VGG16__, __densenet121__. Какой дает лучшее качество?\n",
        "\n",
        "Итак, вы обучили модель предсказывать кропы, например, размера 256x256, качество мерили тоже на кропах. Но как исходная цель - нужно уметь делать предсказания на всю картинку. Как решить проблему и есть ли она вообще? Первый приходящий в голову вариант - можно проходиться по картинке окном в 256x256 пикселей и сохранять предсказания на всю большую картинку. Но можно сделать проще, если ответить на вопрос: работает ли полностью сверточная сеть на картинках произвольного размера(с добиванием до кратности паддингами)? Почему не работали сети для классификации?\n",
        "\n",
        "4. Напоследок, можете попробовать технику под названием __Test Time Augmentation__. Сделайте предсказание картинки, сохраните его. Попробуйте сделать flip картинки, и предсказать флипнутое изображение. Что будет если усреднить результаты этих двух предсказаний? Улучшится ли качество?"
      ]
    },
    {
      "metadata": {
        "id": "Gb-q0KUVZ00K",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "keTJW1ceZ00N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h3 style=\"text-align: center;\"><b>Ваше решение</b></h3>"
      ]
    },
    {
      "metadata": {
        "id": "rIE3yd-RZ00P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LMPUwDfLZ00V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CNIjW45EZ00Y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}